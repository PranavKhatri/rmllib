{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "A simple example that demostrates (a) how to load existing data, or (b) generate your own dataset, followed by a learning task with 4 models.\n",
    "\n",
    "### Load other modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas\n",
    "import numpy.random as random\n",
    "import sklearn.metrics\n",
    "import time\n",
    "pandas.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RML Specific modules\n",
    "\n",
    "First several modules are related to generating the datasets, then a single conditional model is passed to collective inference and semi-supervised methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rmllib.data.load import BostonMedians\n",
    "from rmllib.data.generate import BayesSampleDataset\n",
    "from rmllib.data.generate import edge_rejection_generator\n",
    "from rmllib.models.conditional import RelationalNaiveBayes\n",
    "from rmllib.models.collective_inference import VariationalInference\n",
    "from rmllib.models.semi_supervised import ExpectationMaximization\n",
    "\n",
    "# Seed numpy\n",
    "random.seed(16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two example datasets\n",
    "\n",
    "One augments the boston housing dataset by adding some network connections, the other is fully generated large network with 1M nodes and ~25M edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Degree: 19.998794\n"
     ]
    }
   ],
   "source": [
    "DATASETS = []\n",
    "\n",
    "DATASETS.append(BostonMedians(name='Boston Medians', subfeatures=['RM', 'AGE'], sparse=True).node_sample_mask(.1))\n",
    "DATASETS.append(BayesSampleDataset(name='Sparse 1,000,000', n_rows=1000000, n_features=3, generator=edge_rejection_generator, density=.00002, sparse=False).node_sample_mask(.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare several models\n",
    "\n",
    "A set of models to compare.  Note that the VI and EM modules are *wrapped* around some underlying method.  For VI, this has the effect of overridding the predict_proba method (of RNB) and for EM it effectly overwrites the .fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = []\n",
    "\n",
    "MODELS.append(RelationalNaiveBayes(name='NB', learn_method='iid', infer_method='iid', calibrate=False))\n",
    "MODELS.append(RelationalNaiveBayes(name='RNB', learn_method='r_iid', infer_method='r_iid', calibrate=False))\n",
    "MODELS.append(VariationalInference(RelationalNaiveBayes)(name='RNB_VI', learn_method='r_iid', calibrate=True))\n",
    "MODELS.append(ExpectationMaximization(VariationalInference(RelationalNaiveBayes))(name='RNB_EM_VI', learn_iter=3, calibrate=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the actual evaluation\n",
    "\n",
    "All of our datasets and models have been setup; perform some evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Evaluation\n",
      "\n",
      "(Boston Medians) NB: Begin Train\n",
      "(Boston Medians) NB Training Time: 0.012000560760498047\n",
      "(Boston Medians) NB Total Time: 0.013000726699829102\n",
      "(Boston Medians) NB Average Prediction: 0.42285631281812075 AUC: 0.8292069557080475\n",
      "(Boston Medians) NB: End Train\n",
      "\n",
      "(Boston Medians) RNB: Begin Train\n",
      "(Boston Medians) RNB Training Time: 0.028999805450439453\n",
      "(Boston Medians) RNB Total Time: 0.037995338439941406\n",
      "(Boston Medians) RNB Average Prediction: 0.4211773768087786 AUC: 0.8507096069868997\n",
      "(Boston Medians) RNB: End Train\n",
      "\n",
      "(Boston Medians) RNB_VI: Begin Train\n",
      "(Boston Medians) RNB_VI Training Time: 0.025997161865234375\n",
      "(Boston Medians) RNB_VI Total Time: 0.1549978256225586\n",
      "(Boston Medians) RNB_VI Average Prediction: 0.5967295120169761 AUC: 0.8853321896444167\n",
      "(Boston Medians) RNB_VI: End Train\n",
      "\n",
      "(Boston Medians) RNB_EM_VI: Begin Train\n",
      "(Boston Medians) RNB_EM_VI Training Time: 0.4390103816986084\n",
      "(Boston Medians) RNB_EM_VI Total Time: 0.5580120086669922\n",
      "(Boston Medians) RNB_EM_VI Average Prediction: 0.6005482745268128 AUC: 0.9199157829070492\n",
      "(Boston Medians) RNB_EM_VI: End Train\n",
      "\n",
      "(Sparse 1,000,000) NB: Begin Train\n",
      "(Sparse 1,000,000) NB Training Time: 0.8490099906921387\n",
      "(Sparse 1,000,000) NB Total Time: 1.7990233898162842\n",
      "(Sparse 1,000,000) NB Average Prediction: 0.49843764108910416 AUC: 0.8426113737752055\n",
      "(Sparse 1,000,000) NB: End Train\n",
      "\n",
      "(Sparse 1,000,000) RNB: Begin Train\n",
      "(Sparse 1,000,000) RNB Training Time: 0.9880161285400391\n",
      "(Sparse 1,000,000) RNB Total Time: 3.956059455871582\n",
      "(Sparse 1,000,000) RNB Average Prediction: 0.4985781738293715 AUC: 0.8432701752926033\n",
      "(Sparse 1,000,000) RNB: End Train\n",
      "\n",
      "(Sparse 1,000,000) RNB_VI: Begin Train\n",
      "(Sparse 1,000,000) RNB_VI Training Time: 1.0120155811309814\n",
      "(Sparse 1,000,000) RNB_VI Total Time: 31.934061527252197\n",
      "(Sparse 1,000,000) RNB_VI Average Prediction: 0.4953843413992739 AUC: 0.8487432950331836\n",
      "(Sparse 1,000,000) RNB_VI: End Train\n",
      "\n",
      "(Sparse 1,000,000) RNB_EM_VI: Begin Train\n",
      "(Sparse 1,000,000) RNB_EM_VI Training Time: 91.2920024394989\n",
      "(Sparse 1,000,000) RNB_EM_VI Total Time: 122.62035870552063\n",
      "(Sparse 1,000,000) RNB_EM_VI Average Prediction: 0.49842232758285643 AUC: 0.8286419158598489\n",
      "(Sparse 1,000,000) RNB_EM_VI: End Train\n",
      "End Evaluation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Begin Evaluation')\n",
    "for dataset in DATASETS:\n",
    "    TRAIN_DATA = dataset.create_training()\n",
    "\n",
    "    for model in MODELS:\n",
    "        print('\\n' + \"(\" + dataset.name + \") \" + model.name + \": Begin Train\")\n",
    "        train_data = TRAIN_DATA.copy()\n",
    "        start_time = time.time()\n",
    "        model.fit(train_data)\n",
    "        print(\"(\" + dataset.name + \") \" + model.name, 'Training Time:', time.time() - start_time)\n",
    "        model.predictions = model.predict_proba(train_data)\n",
    "        print(\"(\" + dataset.name + \") \" + model.name, 'Total Time:', time.time() - start_time)            \n",
    "        print(\"(\" + dataset.name + \") \" + model.name, 'Average Prediction:', model.predictions[:, 1].mean(), 'AUC:', sklearn.metrics.roc_auc_score(dataset.labels.Y[dataset.mask.Unlabeled][1], model.predictions[:, 1]))\n",
    "        print(\"(\" + dataset.name + \") \" + model.name + \": End Train\")\n",
    "\n",
    "print('End Evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rmllib]",
   "language": "python",
   "name": "conda-env-rmllib-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
