{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "A simple example that demostrates (a) how to load existing data, or (b) generate your own dataset, followed by a learning task with 4 models.\n",
    "\n",
    "### Load other modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas\n",
    "import numpy.random as random\n",
    "import sklearn.metrics\n",
    "import time\n",
    "pandas.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RML Specific modules\n",
    "\n",
    "First several modules are related to generating the datasets, then a single conditional model is passed to collective inference and semi-supervised methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rmllib.data.load import BostonMedians\n",
    "from rmllib.data.generate import BayesSampleDataset\n",
    "from rmllib.data.generate import edge_rejection_generator\n",
    "from rmllib.models.conditional import RelationalNaiveBayes\n",
    "from rmllib.models.collective_inference import VariationalInference\n",
    "from rmllib.models.semi_supervised import ExpectationMaximization\n",
    "\n",
    "# Seed numpy\n",
    "random.seed(16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two example datasets\n",
    "\n",
    "One augments the boston housing dataset by adding some network connections, the other is fully generated large network with 1M nodes and ~25M edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Degree: 19.998794\n"
     ]
    }
   ],
   "source": [
    "DATASETS = []\n",
    "\n",
    "DATASETS.append(BostonMedians(name='Boston Medians', subfeatures=['RM', 'AGE'], sparse=True).node_sample_mask(.1))\n",
    "DATASETS.append(BayesSampleDataset(name='Sparse 1,000,000', n_rows=1000000, n_features=3, generator=edge_rejection_generator, density=.00002, sparse=False).node_sample_mask(.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare several models\n",
    "\n",
    "A set of models to compare.  Note that the VI and EM modules are *wrapped* around some underlying method.  For VI, this has the effect of overridding the predict_proba method (of RNB) and for EM it effectly overwrites the .fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = []\n",
    "\n",
    "MODELS.append(RelationalNaiveBayes(name='NB', learn_method='iid', infer_method='iid', calibrate=False))\n",
    "MODELS.append(RelationalNaiveBayes(name='RNB', learn_method='r_iid', infer_method='r_iid', calibrate=False))\n",
    "MODELS.append(VariationalInference(RelationalNaiveBayes)(name='RNB_VI', learn_method='r_iid', calibrate=True))\n",
    "MODELS.append(ExpectationMaximization(VariationalInference(RelationalNaiveBayes))(name='RNB_EM_VI', learn_iter=3, calibrate=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the actual evaluation\n",
    "\n",
    "All of our datasets and models have been setup; perform some evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Begin Evaluation')\n",
    "for dataset in DATASETS:\n",
    "    TRAIN_DATA = dataset.create_training()\n",
    "\n",
    "    for model in MODELS:\n",
    "        print('\\n' + \"(\" + dataset.name + \") \" + model.name + \": Begin Train\")\n",
    "        train_data = TRAIN_DATA.copy()\n",
    "        start_time = time.time()\n",
    "        model.fit(train_data)\n",
    "        print(\"(\" + dataset.name + \") \" + model.name, 'Training Time:', time.time() - start_time)\n",
    "        model.predictions = model.predict_proba(train_data)\n",
    "        print(\"(\" + dataset.name + \") \" + model.name, 'Total Time:', time.time() - start_time)            \n",
    "        print(\"(\" + dataset.name + \") \" + model.name, 'Average Prediction:', model.predictions[:, 1].mean(), 'AUC:', sklearn.metrics.roc_auc_score(dataset.labels.Y[dataset.mask.Unlabeled][1], model.predictions[:, 1]))\n",
    "        print(\"(\" + dataset.name + \") \" + model.name + \": End Train\")\n",
    "\n",
    "print('End Evaluation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rmllib]",
   "language": "python",
   "name": "conda-env-rmllib-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
